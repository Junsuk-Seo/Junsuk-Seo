{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# EEMD + LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353f79f",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Input file: Historical Product Demand.csv\n",
    "\n",
    "Description: CSV data file containing product demand for encoded product id's\n",
    "\n",
    "Size of Data: (1048575, 5)\n",
    "\n",
    "Features: Product_Code, Warehouse, Product_Category, Date, Order_Demand\n",
    "\n",
    "Period: 2012-01-01 ~ 2017-01-09\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba9ee40",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "# Save the log\n",
    "import os\n",
    "\n",
    "# EEMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MSE\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Metric \n",
    "# Metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58e094",
   "metadata": {},
   "source": [
    "## Data Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c8f1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product_Code</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Order_Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-05 00:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-05 03:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1633.403702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-05 06:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1628.665789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-05 09:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1587.586651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-05 12:00:00</td>\n",
       "      <td>Product_0025</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1513.949924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116387</th>\n",
       "      <td>2016-12-26 12:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1810.945746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116388</th>\n",
       "      <td>2016-12-26 15:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1626.979543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116389</th>\n",
       "      <td>2016-12-26 18:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1420.229634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116390</th>\n",
       "      <td>2016-12-26 21:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1206.795489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116391</th>\n",
       "      <td>2016-12-27 00:00:00</td>\n",
       "      <td>Product_2004</td>\n",
       "      <td>Category_005</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116392 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date  Product_Code Product_Category  Order_Demand\n",
       "0      2012-01-05 00:00:00  Product_0025     Category_005   1600.000000\n",
       "1      2012-01-05 03:00:00  Product_0025     Category_005   1633.403702\n",
       "2      2012-01-05 06:00:00  Product_0025     Category_005   1628.665789\n",
       "3      2012-01-05 09:00:00  Product_0025     Category_005   1587.586651\n",
       "4      2012-01-05 12:00:00  Product_0025     Category_005   1513.949924\n",
       "...                    ...           ...              ...           ...\n",
       "116387 2016-12-26 12:00:00  Product_2004     Category_005   1810.945746\n",
       "116388 2016-12-26 15:00:00  Product_2004     Category_005   1626.979543\n",
       "116389 2016-12-26 18:00:00  Product_2004     Category_005   1420.229634\n",
       "116390 2016-12-26 21:00:00  Product_2004     Category_005   1206.795489\n",
       "116391 2016-12-27 00:00:00  Product_2004     Category_005   1000.000000\n",
       "\n",
       "[116392 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Loading\n",
    "df = pd.read_csv('HPD_Augmented_0416.csv')\n",
    "# convert the string to the datetype\n",
    "df['Date'] = df['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed38f8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116392 entries, 0 to 116391\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count   Dtype         \n",
      "---  ------            --------------   -----         \n",
      " 0   Date              116392 non-null  datetime64[ns]\n",
      " 1   Product_Code      116392 non-null  object        \n",
      " 2   Product_Category  116392 non-null  object        \n",
      " 3   Order_Demand      116392 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "-------------------------\n",
      "\n",
      "The Number of unique\n",
      "-------------------------\n",
      "Product code:\t 8\n",
      "Category:\t 5\n",
      "-------------------------\n",
      "The Product Code:\n",
      "\n",
      "1 Product_0025\n",
      "2 Product_0739\n",
      "3 Product_0901\n",
      "4 Product_1154\n",
      "5 Product_1248\n",
      "6 Product_1295\n",
      "7 Product_1378\n",
      "8 Product_2004\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print('-------------------------')\n",
    "print(\"\")\n",
    "print(\"The Number of unique\")\n",
    "print('-------------------------')\n",
    "print('Product code:\\t', df.Product_Code.nunique())\n",
    "print('Category:\\t', df.Product_Category.nunique())\n",
    "print('-------------------------')\n",
    "print(\"The Product Code:\")\n",
    "print(\"\")\n",
    "for i, code in enumerate(df['Product_Code'].unique()):\n",
    "    print(i+1, code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76850788",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07916726",
   "metadata": {},
   "source": [
    "## EEMD\n",
    "    * 시계열 그래프를 ensembled IMF (앙상블 내재모드 함수)로 분해\n",
    "    * n 개의 eIMFs와  1개의 Residual 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b907c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수요 그래프를 n개의 앙상블된 내재모드함수(IMF)로 분해\n",
    "# 그래프의 변동성이 클수록, IMF의 개수 증가\n",
    "def eemd_fit(df, trials=100, max_imf=-1):\n",
    "    \n",
    "    # Define signal\n",
    "    t = np.array(df['Date']) # 날짜\n",
    "    s = np.array(df['Order_Demand']) # 수요량\n",
    "    \n",
    "    # EEMD 객체 생성\n",
    "    eemd = EEMD(trials=trials) # trials: EMD 횟수\n",
    "    \n",
    "    # 극값을 감지하는 방법으로 parabolic 방법을 선택\n",
    "    emd = eemd.EMD\n",
    "    emd.extrema_detection=\"parabol\"\n",
    "    \n",
    "    # eIMFs로 분해\n",
    "    eIMFs = eemd.eemd(s, t, max_imf=max_imf) # max_imf: IMF 제한 개수(-1: 없음)\n",
    "    nIMFs = eIMFs.shape[0] # eIMF의 개수\n",
    "    \n",
    "    # 분해된 eIMFs와 잔차를 변수에 할당\n",
    "    imfs, residue = eemd.get_imfs_and_residue()\n",
    "    \n",
    "    # 앙상블 IMFs 들의 DataFrame 생성\n",
    "    all_eIMFs_df = pd.DataFrame(eIMFs).transpose()\n",
    "    all_eIMFs_df[nIMFs] = residue # residue 열 마지막 열로 추가\n",
    "    #all_eIMFs_df.set_index(df['Date'], inplace=True) # 날짜를 index로 setting\n",
    "    all_eIMFs_df.insert(0, 'Date', df['Date']) # Date 열 추가\n",
    "    \n",
    "    return all_eIMFs_df, nIMFs # eIMF+Residue들로 이루어진 df, eIMF(Residue포함)의 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76e4a8c",
   "metadata": {},
   "source": [
    "### eIMFs 데이터프레임 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265e715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eIMF들을 추출하여, Date와 y로 이루어진 데이터프레임 추출하고 딕셔너리에 저장\n",
    "def extract_eIMFs(all_eIMFs_df, nIMFs):\n",
    "    all_eIMFs_dict = {}\n",
    "    # IMF개수+Residue(1) 만큼 반복\n",
    "    for i in range(nIMFs+1):\n",
    "        tmp_df = all_eIMFs_df[['Date', i]] # n번째 eIMF에 해당하는 날짜와 값 추출\n",
    "        tmp_df.columns=['Date', 'y'] # i -> y 로 열이름 변경\n",
    "        all_eIMFs_dict[f'eIMFs_{i}'] = tmp_df # n번째 eIMF 정보(마지막은 Residue) 딕셔너리에 저장\n",
    "        \n",
    "    return all_eIMFs_dict # {eIMFs_1: df1, eIMFs_2: df2, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4680cb42",
   "metadata": {},
   "source": [
    "### Split the train and test set\n",
    "- Input\n",
    "     data: dataframe with dates and Demand data\n",
    "     \n",
    "- output\n",
    "    - train:  2012-01-01 ~ 2015-06/30 \n",
    "    - Valid:  2015-07-01 ~ 2015-12-31\n",
    "    - test :  2016-01-01 ~ 2017-01-06 \n",
    "    \n",
    "     \n",
    "- time_steps: # of the input time steps \n",
    "- for_periods: # of the output time steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbe9b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_val_test(eIMF_df, time_steps): \n",
    "\n",
    "    ts_train_end = len(eIMF_df[eIMF_df['Date']<'2015-07-01']) # train 데이터 종료 인덱스\n",
    "    ts_val_end = len(eIMF_df[eIMF_df['Date']<'2016-01-01']) # validation 데이터 종료 인덱스\n",
    "    ts = eIMF_df.filter(['y']).values # y(수요량) 값\n",
    "    \n",
    "    # Minmax로 0~1 사이에 값이 오도록 정규화\n",
    "    sc = MinMaxScaler() # 객체 생성\n",
    "    ts_scaled = sc.fit_transform(ts) # 전체 y값 정규화\n",
    "    \n",
    "    # Train Data\n",
    "    ts_train_scaled = ts_scaled[:ts_train_end,:]\n",
    "\n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    for i in range(time_steps, ts_train_end): \n",
    "        X_train.append(ts_train_scaled[i-time_steps:i,0]) # time steps 만큼 sliding window\n",
    "        y_train.append(ts_train_scaled[i,0])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    # Reshape X_train for LSTM -> (batch_size, time_steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "\n",
    "    # Validation Data\n",
    "    ts_val_scaled = ts_scaled[ts_train_end : ts_val_end, :]\n",
    "\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    for i in range(time_steps, len(ts_val_scaled)):\n",
    "        X_val.append(ts_val_scaled[i-time_steps : i, 0])\n",
    "        y_val.append(ts_val_scaled[i, 0])\n",
    "\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "    # Reshape X_val for LSTM -> (batch_size, time_steps, features)\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1],1))\n",
    "    \n",
    "    # Test Data\n",
    "    ts_test_scaled = ts_scaled[ts_val_end:,:]\n",
    "\n",
    "    X_test = []\n",
    "    y_test = eIMF_df.iloc[ts_val_end+time_steps:,:]\n",
    "    y_test.loc[:, 'y_norm'] = ts_test_scaled[time_steps:].reshape(-1).copy()\n",
    "\n",
    "    for i in range(time_steps, len(ts_test_scaled)):\n",
    "        X_test.append(ts_test_scaled[i-time_steps : i, 0])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da9661",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01113fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(X_train, y_train, X_val, y_val, X_test, sc, epochs=10):\n",
    "    # LSTM 모델 객체 생성\n",
    "    my_LSTM_model = Sequential() \n",
    "    \n",
    "    # 첫 번째 LSTM 레이어 구성\n",
    "    # 활성화 함수는 ReLU를 사용하며, return_sequences=True로 지정하여 다음 LSTM 레이어의 입력으로 사용할 수 있도록 함\n",
    "    my_LSTM_model.add(LSTM(512, activation='relu',return_sequences=True, input_shape=(X_train.shape[1],1)))\n",
    "    \n",
    "    # 두 번째 LSTM 레이어 구성\n",
    "    # 활성화 함수는 ReLU를 사용하며, return_sequences=False로 지정하여 마지막 LSTM 레이어임을 나타냄\n",
    "    my_LSTM_model.add(LSTM(256, activation = 'relu',return_sequences=False))\n",
    "    \n",
    "    # Fully connected 레이어들 추가\n",
    "    # 마지막 레이어에서는 출력의 unit 개수를 1로 설정하여 1개의 값을 출력\n",
    "    my_LSTM_model.add(Dense(128))\n",
    "    my_LSTM_model.add(Dense(64))\n",
    "    my_LSTM_model.add(Dense(32))\n",
    "    my_LSTM_model.add(Dense(1))\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    my_LSTM_model.compile(optimizer = \"Adam\", # Adam optimizer 사용\n",
    "                         loss = 'mean_squared_error', # 손실 함수로는 평균 제곱 오차 사용\n",
    "                          metrics=['mape','mae']) # 성능 지표로는 MAPE와 MAE를 사용\n",
    "    #조기종료 조건\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # 모델 Fitting\n",
    "    my_LSTM_model.fit(X_train, # 입력 데이터\n",
    "                      y_train, # 출력 데이터\n",
    "                      epochs = epochs, # epoch 수\n",
    "                      batch_size = 16, # batch size\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      callbacks=[early_stopping],# validation에 따른 조기종료\n",
    "                      verbose = 1) # 학습 상태를 출력\n",
    "    \n",
    "    # Test 데이터 예측\n",
    "    LSTM_prediction = my_LSTM_model.predict(X_test) # 예측값 얻기\n",
    "    LSTM_prediction_normalized = LSTM_prediction # 예측값을 저장하되, normalize된 값 저장\n",
    "    LSTM_prediction = sc.inverse_transform(LSTM_prediction) # denormalize된 예측값 저장\n",
    "    \n",
    "    # 모델 객체와 예측값 반환\n",
    "    return my_LSTM_model, LSTM_prediction, LSTM_prediction_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b922e",
   "metadata": {},
   "source": [
    "### EEMD+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a404016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEMD_LSTM(all_eIMFs_dict, time_steps, epochs):\n",
    "\n",
    "    model_dict = {}\n",
    "    pred_dict = {}\n",
    "    \n",
    "    # 모든 eIMF에 대해 LSTM 모델 학습 및 예측 실행\n",
    "    for i in all_eIMFs_dict.keys():\n",
    "        print(f'--------Total: 0~{len(all_eIMFs_dict)-1} eIMFs, Now: {i} --------')\n",
    "        \n",
    "        # 현재 eIMF 데이터 가져오기\n",
    "        eIMF_df = all_eIMFs_dict[i]\n",
    "        \n",
    "        # 학습 데이터와 테스트 데이터 분리\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test, sc = ts_train_val_test(eIMF_df, time_steps)\n",
    "        \n",
    "        # LSTM 모델 학습 및 저장\n",
    "        my_LSTM_model, LSTM_prediction, LSTM_prediction_normalized = LSTM_model(X_train, y_train, X_val, y_val, X_test, sc, epochs)\n",
    "        model_dict[i] = my_LSTM_model # 딕셔너리에 모델 정보 저장\n",
    "        \n",
    "        # 예측 결과 저장\n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        pred_df = pd.DataFrame({'Pred': LSTM_prediction.reshape(-1) ,'Pred_norm': LSTM_prediction_normalized.reshape(-1)})\n",
    "        res_df = pd.concat([y_test, pred_df], axis=1)\n",
    "        res_df.set_index('Date', inplace=True)\n",
    "        res_df = res_df.resample('D').first() # 증강된 데이터가 아닌, Actual값들과 비교\n",
    "        pred_dict[i] = res_df\n",
    "        \n",
    "    # 모델과 예측값 딕셔너리 반환\n",
    "    return model_dict, pred_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbd64a0",
   "metadata": {},
   "source": [
    "## Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, pred_dict, all_result_df, normalize=False):\n",
    "    today = date.today()\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    pred_dict['all_result'] = all_result_df\n",
    "    \n",
    "    save_path = os.path.join(\"Result\", product_code+f'_{today.month:02d}{today.day:02d}')\n",
    "    if normalize: save_path += \"_normalized\"\n",
    "        \n",
    "    for i, pred_df in enumerate(pred_dict.values()):\n",
    "        img_n = len(pred_dict)\n",
    "        title = f\"Pred Actual Plot - ({i+1}/{len(pred_dict)})'s eIMF\"\n",
    "        actual = pred_df['y']\n",
    "        pred = pred_df['Pred']\n",
    "        save_name = f'{product_code}_eIMF_{i+1}'\n",
    "        if i == img_n-1:\n",
    "            title = f\"{product_code}-All Result\"\n",
    "            save_name = f'{product_code}_all_result'\n",
    "        if normalize:\n",
    "            title += \"(Normalized)\"\n",
    "            actual = pred_df['y_norm']\n",
    "            pred = pred_df['Pred_norm']\n",
    "            \n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(title, fontsize=20)\n",
    "        plt.xlabel(\"Time\", fontsize=14)\n",
    "        plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "        plt.plot(actual, label ='Actual', alpha=0.6)\n",
    "        plt.plot(pred, label='Prediction', alpha=0.8)\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        # Plot 결과 저장\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        # save the figure\n",
    "        today_date = f'_{today.month:02d}{today.day:02d}'\n",
    "        plt.savefig(os.path.join(save_path, save_name+'.png'))\n",
    "    del pred_dict['all_result']\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd8454",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Metric\n",
    "def mase(training_series, testing_series, prediction_series):\n",
    "    n = training_series.shape[0]\n",
    "    d = np.abs(np.diff(training_series)).sum() / (n-1)\n",
    "    \n",
    "    errors = np.abs(testing_series - prediction_series)\n",
    "    return errors.mean() / d\n",
    "\n",
    "# Model Metric\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_df, normalize):\n",
    "    # 계산된 메트릭을 저장하기 위해 데이터프레임 초기화\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE'])\n",
    "\n",
    "    # 정규화 옵션이 True인 경우 정규화된 데이터 사용, 그렇지 않으면 원래 데이터 사용\n",
    "    if normalize:\n",
    "        actual = pred_df['y_norm']\n",
    "        pred = pred_df['Pred_norm']\n",
    "    else:\n",
    "        actual = pred_df['y']\n",
    "        pred = pred_df['Pred']\n",
    "\n",
    "    # 메트릭 계산\n",
    "    # MASE = mase(np.array(train_series), np.array(actual), pred) \n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = mean_squared_error(actual, pred)**0.5 \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    # RMSLE = mean_squared_log_error(actual, pred)**0.5 \n",
    "\n",
    "    # 계산된 메트릭을 데이터프레임에 추가\n",
    "    tmp_df = pd.DataFrame({'MAPE':[round(MAPE, 2)],\n",
    "                           'RMSE':[round(RMSE, 2)],\n",
    "                           'MAE':[round(MAE, 2)],\n",
    "                           'NRMSE':[round(NRMSE, 2)]})\n",
    "\n",
    "    # 메트릭 데이터프레임에 결과 추가\n",
    "    metric_df = pd.concat([metric_df, tmp_df])\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073bc376",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e45cb6",
   "metadata": {},
   "source": [
    "## Check the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e560ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(product_code, pred_dict, all_result_df, normalize):\n",
    "    today = date.today()\n",
    "    save_path = os.path.join(\"Result\", f\"{product_code}_Metric_{today.month:02d}{today.day:02d}\")\n",
    "    save_name = f'{product_code}_Metric'\n",
    "    \n",
    "    if normalize:\n",
    "        save_name += \"_normalized\"\n",
    "    result_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE'])\n",
    "    for i, pred_df in pred_dict.items():\n",
    "        imf_df = calculate_metrics(pred_df, normalize=normalize)\n",
    "        result_df = pd.concat([result_df, imf_df])\n",
    "    \n",
    "    imf_idx = pd.Index(['eIMF_'+str(i+1) for i in range(len(pred_dict))]) # changed result_dict to pred_dict\n",
    "    result_df.index = imf_idx # Assign the created index to result_df\n",
    "    result_df = pd.concat([result_df, calculate_metrics(all_result_df, normalize=normalize)], axis=0)\n",
    "    result_df = result_df.rename(index={result_df.index[-1]: 'All'}) # 마지막 행은 all\n",
    "    # 결과 저장\n",
    "    # create a directory if not exists\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    # save the figure\n",
    "    result_df.to_csv(os.path.join(save_path, save_name+'.csv')) # added os.path.join and fixed string literal mistake\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_EEMD_LSTM(product_code, eemd_trials=100, time_steps=30, epochs=15, normalize=False, plot=False, metric=False):\n",
    "\n",
    "    product_code = product_code # 예측하고자 하는 코드 입력\n",
    "    product_df = df[df['Product_Code']== product_code].reset_index(drop=True)\n",
    "    \n",
    "    # EEMD 수행\n",
    "    all_eIMFs_df, nIMFs = eemd_fit(product_df, eemd_trials)\n",
    "    # EEMD 결과에서 각 eIMFs' DF 추출\n",
    "    all_eIMFs_dict = extract_eIMFs(all_eIMFs_df, nIMFs)\n",
    "    # EEMD+LSTM 실행\n",
    "    model_dict, pred_dict = EEMD_LSTM(all_eIMFs_dict, time_steps, epochs) #dictionary, time_steps, epochs\n",
    "    all_result_df = make_all_result_df(pred_dict)\n",
    "    \n",
    "    result_df = make_metric_df(product_code, pred_dict, all_result_df, normalize)\n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, normalize)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40503729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_result_df(pred_dict):\n",
    "    all_df = pd.DataFrame()\n",
    "    for tmp_df in pred_dict.values():\n",
    "        all_df = pd.concat([all_df, tmp_df], axis=1)\n",
    "    pred_df = all_df['Pred'].sum(axis=1)\n",
    "    actual_df = all_df['y'].sum(axis=1)\n",
    "    \n",
    "    all_result_df = pd.DataFrame({'Pred': pred_df, 'y': actual_df})\n",
    "    all_result_df.loc[all_result_df['Pred']<0, 'Pred']=0 # 음수 예측 값은 0으로 대치\n",
    "    \n",
    "    # 날짜(Date) 열은 정규화하지 않으므로 제외\n",
    "    result_norm = all_result_df[['Pred', 'y']]\n",
    "    \n",
    "    # MinMaxScaler를 이용하여 정규화합니다.\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(result_norm)\n",
    "    \n",
    "    # 정규화된 데이터를 데이터 프레임에 반영합니다.\n",
    "    all_result_df['Pred_norm'] = normalized_data[:,0]\n",
    "    all_result_df['y_norm'] = normalized_data[:,1]\n",
    "    return all_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2bffe",
   "metadata": {},
   "source": [
    "## Whole Process\n",
    "    - product_code에 str으로 예측하고자 하는 코드를 입력\n",
    "    - ['Product_0025', 'Product_0739', 'Product_0901', 'Product_1154',\n",
    "       'Product_1248', 'Product_1295', 'Product_1378', 'Product_2004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "095eda0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Total: 0~14 eIMFs, Now: eIMFs_0 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 162s 251ms/step - loss: 0.0147 - mape: 17.8358 - mae: 0.0945 - val_loss: 0.0128 - val_mape: 409291.2812 - val_mae: 0.0889\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 170s 268ms/step - loss: 0.0132 - mape: 17.2247 - mae: 0.0909 - val_loss: 0.0145 - val_mape: 370284.9375 - val_mae: 0.0957\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 164s 258ms/step - loss: 0.0129 - mape: 17.0892 - mae: 0.0902 - val_loss: 0.0156 - val_mape: 362883.5625 - val_mae: 0.0992\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 153s 241ms/step - loss: 0.0117 - mape: 16.2756 - mae: 0.0861 - val_loss: 0.0095 - val_mape: 277786.0938 - val_mae: 0.0770\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 153s 240ms/step - loss: 0.0097 - mape: 14.6471 - mae: 0.0780 - val_loss: 0.0093 - val_mape: 218415.4219 - val_mae: 0.0763\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 153s 241ms/step - loss: 0.0093 - mape: 14.4084 - mae: 0.0768 - val_loss: 0.0101 - val_mape: 238020.1250 - val_mae: 0.0803\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 160s 251ms/step - loss: 0.0093 - mape: 14.3391 - mae: 0.0764 - val_loss: 0.0094 - val_mape: 187651.3750 - val_mae: 0.0765\n",
      "Epoch 8/20\n",
      "635/635 [==============================] - 160s 253ms/step - loss: 0.0094 - mape: 14.4192 - mae: 0.0769 - val_loss: 0.0090 - val_mape: 198138.9688 - val_mae: 0.0754\n",
      "Epoch 9/20\n",
      "635/635 [==============================] - 160s 252ms/step - loss: 0.0093 - mape: 14.3312 - mae: 0.0766 - val_loss: 0.0092 - val_mape: 225425.3125 - val_mae: 0.0762\n",
      "Epoch 10/20\n",
      "635/635 [==============================] - 160s 251ms/step - loss: 0.0092 - mape: 14.2107 - mae: 0.0760 - val_loss: 0.0091 - val_mape: 206852.8594 - val_mae: 0.0760\n",
      "Epoch 11/20\n",
      "635/635 [==============================] - 160s 251ms/step - loss: 0.0092 - mape: 14.2914 - mae: 0.0763 - val_loss: 0.0093 - val_mape: 177252.5312 - val_mae: 0.0761\n",
      "92/92 [==============================] - 12s 131ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_1 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 160s 249ms/step - loss: 0.0025 - mape: 5.0589 - mae: 0.0276 - val_loss: 0.0025 - val_mape: 398824.0625 - val_mae: 0.0247\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 158s 248ms/step - loss: 8.7305e-04 - mape: 4.0802 - mae: 0.0222 - val_loss: 0.0025 - val_mape: 395861.8750 - val_mae: 0.0253\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 156s 246ms/step - loss: 8.7805e-04 - mape: 4.1050 - mae: 0.0223 - val_loss: 0.0025 - val_mape: 380476.0625 - val_mae: 0.0255\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 8.4478e-04 - mape: 3.9945 - mae: 0.0217 - val_loss: 0.0025 - val_mape: 388604.5938 - val_mae: 0.0250\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 8.4233e-04 - mape: 3.9976 - mae: 0.0218 - val_loss: 0.0025 - val_mape: 378888.1250 - val_mae: 0.0249\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 8.4204e-04 - mape: 4.0071 - mae: 0.0218 - val_loss: 0.0028 - val_mape: 369763.0625 - val_mae: 0.0297\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 8.3286e-04 - mape: 3.9590 - mae: 0.0215 - val_loss: 0.0024 - val_mape: 384561.0000 - val_mae: 0.0244\n",
      "Epoch 8/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 8.1128e-04 - mape: 3.8931 - mae: 0.0212 - val_loss: 0.0024 - val_mape: 384145.6250 - val_mae: 0.0244\n",
      "Epoch 9/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 7.9892e-04 - mape: 3.8742 - mae: 0.0211 - val_loss: 0.0026 - val_mape: 373924.1250 - val_mae: 0.0267\n",
      "Epoch 10/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 8.1676e-04 - mape: 3.9348 - mae: 0.0214 - val_loss: 0.0024 - val_mape: 386334.1875 - val_mae: 0.0248\n",
      "Epoch 11/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 8.0181e-04 - mape: 3.8872 - mae: 0.0211 - val_loss: 0.0024 - val_mape: 386458.3125 - val_mae: 0.0248\n",
      "92/92 [==============================] - 12s 123ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_2 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 154s 239ms/step - loss: 0.0020 - mape: 5.5711 - mae: 0.0250 - val_loss: 6.6022e-04 - val_mape: 157178.8594 - val_mae: 0.0108\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 1.9590e-04 - mape: 2.1971 - mae: 0.0100 - val_loss: 3.2621e-04 - val_mape: 88718.3984 - val_mae: 0.0128\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 152s 240ms/step - loss: 9.7060e-05 - mape: 1.5800 - mae: 0.0072 - val_loss: 1.3676e-04 - val_mape: 67805.5234 - val_mae: 0.0070\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 152s 240ms/step - loss: 6.5346e-05 - mape: 1.3580 - mae: 0.0062 - val_loss: 8.6474e-05 - val_mape: 58477.6992 - val_mae: 0.0054\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 4.2908e-05 - mape: 1.0802 - mae: 0.0050 - val_loss: 7.9533e-05 - val_mape: 47220.5430 - val_mae: 0.0055\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 2.9420e-05 - mape: 0.9077 - mae: 0.0042 - val_loss: 1.1270e-04 - val_mape: 31259.9473 - val_mae: 0.0091\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 2.8526e-05 - mape: 0.9068 - mae: 0.0042 - val_loss: 4.7560e-05 - val_mape: 47121.5938 - val_mae: 0.0029\n",
      "Epoch 8/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 3.1466e-05 - mape: 0.9369 - mae: 0.0043 - val_loss: 7.9037e-05 - val_mape: 37290.9141 - val_mae: 0.0070\n",
      "Epoch 9/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 2.4496e-05 - mape: 0.8480 - mae: 0.0039 - val_loss: 9.3045e-05 - val_mape: 41774.3125 - val_mae: 0.0078\n",
      "Epoch 10/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 2.0515e-05 - mape: 0.7605 - mae: 0.0035 - val_loss: 6.3301e-05 - val_mape: 38619.3789 - val_mae: 0.0052\n",
      "92/92 [==============================] - 11s 122ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_3 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 154s 239ms/step - loss: 0.0026 - mape: 24919.7480 - mae: 0.0284 - val_loss: 1.4292e-04 - val_mape: 3.5067 - val_mae: 0.0081\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 6.5417e-05 - mape: 5325.1313 - mae: 0.0062 - val_loss: 9.8219e-05 - val_mape: 2.5477 - val_mae: 0.0082\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 5.1407e-05 - mape: 3956.9990 - mae: 0.0056 - val_loss: 3.9817e-05 - val_mape: 1.5901 - val_mae: 0.0042\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 3.5033e-05 - mape: 1708.0909 - mae: 0.0046 - val_loss: 3.8966e-05 - val_mape: 1.5936 - val_mae: 0.0041\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 4.2969e-05 - mape: 1501.3359 - mae: 0.0051 - val_loss: 2.5112e-05 - val_mape: 1.4986 - val_mae: 0.0030\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 3.2958e-05 - mape: 2550.3564 - mae: 0.0044 - val_loss: 2.0457e-05 - val_mape: 1.0902 - val_mae: 0.0027\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 3.0721e-05 - mape: 92.8885 - mae: 0.0044 - val_loss: 6.6517e-05 - val_mape: 2.2706 - val_mae: 0.0072\n",
      "Epoch 8/20\n",
      "635/635 [==============================] - 152s 240ms/step - loss: 1.9350e-05 - mape: 1165.1113 - mae: 0.0034 - val_loss: 1.5241e-05 - val_mape: 1.0582 - val_mae: 0.0022\n",
      "Epoch 9/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 2.0662e-05 - mape: 89.9555 - mae: 0.0036 - val_loss: 1.3756e-05 - val_mape: 1.0136 - val_mae: 0.0022\n",
      "Epoch 10/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 1.9509e-05 - mape: 1687.6829 - mae: 0.0034 - val_loss: 1.8519e-05 - val_mape: 1.3872 - val_mae: 0.0035\n",
      "Epoch 11/20\n",
      "635/635 [==============================] - 153s 241ms/step - loss: 2.3505e-05 - mape: 17.6315 - mae: 0.0037 - val_loss: 4.4095e-05 - val_mape: 1.8647 - val_mae: 0.0057\n",
      "Epoch 12/20\n",
      "635/635 [==============================] - 152s 240ms/step - loss: 1.9381e-05 - mape: 129.3255 - mae: 0.0034 - val_loss: 1.3435e-05 - val_mape: 0.7932 - val_mae: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 2.0670e-05 - mape: 759.0223 - mae: 0.0035 - val_loss: 1.4785e-05 - val_mape: 1.1012 - val_mae: 0.0025\n",
      "Epoch 14/20\n",
      "635/635 [==============================] - 148s 233ms/step - loss: 1.2116e-05 - mape: 155.7565 - mae: 0.0028 - val_loss: 1.3607e-05 - val_mape: 1.0531 - val_mae: 0.0022\n",
      "Epoch 15/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 1.3623e-05 - mape: 316.6294 - mae: 0.0028 - val_loss: 1.9184e-05 - val_mape: 1.2881 - val_mae: 0.0031\n",
      "92/92 [==============================] - 12s 128ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_4 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 151s 235ms/step - loss: 0.0022 - mape: 4888.5044 - mae: 0.0209 - val_loss: 6.8326e-05 - val_mape: 1.4945 - val_mae: 0.0060\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 7.5625e-05 - mape: 1584.0330 - mae: 0.0068 - val_loss: 1.7606e-04 - val_mape: 2.6637 - val_mae: 0.0118\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 5.9355e-05 - mape: 2213.6013 - mae: 0.0060 - val_loss: 8.4161e-05 - val_mape: 1.7366 - val_mae: 0.0063\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 148s 233ms/step - loss: 4.6370e-05 - mape: 951.8594 - mae: 0.0053 - val_loss: 2.1863e-05 - val_mape: 0.8461 - val_mae: 0.0033\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 148s 234ms/step - loss: 4.7123e-05 - mape: 3076.9163 - mae: 0.0053 - val_loss: 1.2283e-04 - val_mape: 2.2051 - val_mae: 0.0103\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 148s 233ms/step - loss: 2.8615e-05 - mape: 992.0715 - mae: 0.0042 - val_loss: 8.5760e-05 - val_mape: 1.9342 - val_mae: 0.0088\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 148s 233ms/step - loss: 3.2445e-05 - mape: 58.9576 - mae: 0.0044 - val_loss: 2.8547e-05 - val_mape: 0.9414 - val_mae: 0.0043\n",
      "92/92 [==============================] - 12s 125ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_5 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 151s 234ms/step - loss: 0.0012 - mape: 3.6737 - mae: 0.0154 - val_loss: 3.1402e-04 - val_mape: 87169.7812 - val_mae: 0.0097\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 4.1159e-05 - mape: 1.1748 - mae: 0.0050 - val_loss: 2.1819e-04 - val_mape: 80343.3438 - val_mae: 0.0066\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 148s 234ms/step - loss: 3.5517e-05 - mape: 1.1009 - mae: 0.0047 - val_loss: 2.3947e-04 - val_mape: 84083.9531 - val_mae: 0.0078\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 3.6344e-05 - mape: 1.0523 - mae: 0.0045 - val_loss: 2.1690e-04 - val_mape: 81715.4766 - val_mae: 0.0065\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 1.8995e-05 - mape: 0.7850 - mae: 0.0034 - val_loss: 3.0793e-04 - val_mape: 75298.6875 - val_mae: 0.0138\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 3.0012e-05 - mape: 0.9247 - mae: 0.0040 - val_loss: 1.9952e-04 - val_mape: 83820.7891 - val_mae: 0.0062\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 148s 234ms/step - loss: 2.6671e-05 - mape: 0.9184 - mae: 0.0040 - val_loss: 1.8053e-04 - val_mape: 81428.7734 - val_mae: 0.0061\n",
      "Epoch 8/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 1.9078e-05 - mape: 0.7252 - mae: 0.0031 - val_loss: 2.0575e-04 - val_mape: 87921.6797 - val_mae: 0.0067\n",
      "Epoch 9/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 1.4783e-05 - mape: 0.6808 - mae: 0.0030 - val_loss: 2.0762e-04 - val_mape: 95042.1719 - val_mae: 0.0037\n",
      "Epoch 10/20\n",
      "635/635 [==============================] - 149s 234ms/step - loss: 1.7534e-05 - mape: 0.7510 - mae: 0.0032 - val_loss: 1.9868e-04 - val_mape: 90697.9844 - val_mae: 0.0053\n",
      "92/92 [==============================] - 12s 123ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_6 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 152s 236ms/step - loss: 0.0013 - mape: 3.6455 - mae: 0.0155 - val_loss: 2.3249e-04 - val_mape: 83015.2656 - val_mae: 0.0066\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 149s 235ms/step - loss: 2.5971e-05 - mape: 0.9166 - mae: 0.0039 - val_loss: 2.2361e-04 - val_mape: 83349.8438 - val_mae: 0.0071\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 3.6015e-05 - mape: 1.0298 - mae: 0.0045 - val_loss: 4.2651e-04 - val_mape: 108975.5469 - val_mae: 0.0109\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 149s 235ms/step - loss: 1.7172e-05 - mape: 0.7217 - mae: 0.0031 - val_loss: 3.3247e-04 - val_mape: 104666.3516 - val_mae: 0.0054\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 149s 235ms/step - loss: 2.9538e-05 - mape: 0.9256 - mae: 0.0040 - val_loss: 4.8361e-04 - val_mape: 119213.1250 - val_mae: 0.0089\n",
      "92/92 [==============================] - 11s 121ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_7 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 152s 236ms/step - loss: 0.0016 - mape: 2061.1003 - mae: 0.0129 - val_loss: 3.5648e-05 - val_mape: 1.9078 - val_mae: 0.0038\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 150s 235ms/step - loss: 2.4138e-05 - mape: 258.4784 - mae: 0.0035 - val_loss: 6.8614e-05 - val_mape: 3.0937 - val_mae: 0.0056\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 2.3102e-05 - mape: 51.9544 - mae: 0.0035 - val_loss: 3.0989e-05 - val_mape: 1.8442 - val_mae: 0.0038\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 3.4660e-05 - mape: 408.5378 - mae: 0.0042 - val_loss: 1.3618e-05 - val_mape: 1.3027 - val_mae: 0.0021\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 150s 236ms/step - loss: 1.8332e-05 - mape: 364.6861 - mae: 0.0027 - val_loss: 1.2247e-05 - val_mape: 1.1921 - val_mae: 0.0025\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 150s 236ms/step - loss: 3.6798e-05 - mape: 218.4702 - mae: 0.0032 - val_loss: 2.6738e-04 - val_mape: 2.6313 - val_mae: 0.0131\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 150s 236ms/step - loss: 6.3576e-05 - mape: 343.3891 - mae: 0.0045 - val_loss: 1.3418e-04 - val_mape: 3.1568 - val_mae: 0.0108\n",
      "Epoch 8/20\n",
      "635/635 [==============================] - 150s 236ms/step - loss: 3.6874e-05 - mape: 183.8352 - mae: 0.0034 - val_loss: 2.4018e-05 - val_mape: 1.7011 - val_mae: 0.0044\n",
      "92/92 [==============================] - 11s 119ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_8 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 153s 237ms/step - loss: 0.0012 - mape: 199.4638 - mae: 0.0116 - val_loss: 2.4059e-05 - val_mape: 1.1859 - val_mae: 0.0042\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 2.9520e-05 - mape: 427.8760 - mae: 0.0039 - val_loss: 5.6478e-06 - val_mape: 0.7508 - val_mae: 0.0017\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 3.7639e-05 - mape: 176.6607 - mae: 0.0043 - val_loss: 2.3848e-05 - val_mape: 1.5241 - val_mae: 0.0042\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 4.6889e-05 - mape: 81.3629 - mae: 0.0044 - val_loss: 9.3366e-05 - val_mape: 2.9544 - val_mae: 0.0085\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 150s 236ms/step - loss: 2.1586e-05 - mape: 819.3508 - mae: 0.0033 - val_loss: 2.8875e-05 - val_mape: 1.9866 - val_mae: 0.0044\n",
      "92/92 [==============================] - 11s 120ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_9 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 153s 238ms/step - loss: 0.0011 - mape: 2387.0134 - mae: 0.0107 - val_loss: 8.2338e-05 - val_mape: 1.4253 - val_mae: 0.0074\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 9.9322e-05 - mape: 4698.1089 - mae: 0.0074 - val_loss: 1.3594e-04 - val_mape: 2.9949 - val_mae: 0.0100\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 4.1723e-05 - mape: 1332.9595 - mae: 0.0049 - val_loss: 4.7019e-05 - val_mape: 0.7865 - val_mae: 0.0047\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 5.2316e-05 - mape: 1342.5063 - mae: 0.0050 - val_loss: 1.0534e-04 - val_mape: 1.9231 - val_mae: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "635/635 [==============================] - 150s 236ms/step - loss: 1.8550e-05 - mape: 619.3061 - mae: 0.0031 - val_loss: 7.4629e-06 - val_mape: 0.3984 - val_mae: 0.0022\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 7.7929e-05 - mape: 205.9742 - mae: 0.0055 - val_loss: 2.7552e-06 - val_mape: 0.3566 - val_mae: 0.0015\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 1.5828e-05 - mape: 417.0357 - mae: 0.0025 - val_loss: 7.9775e-06 - val_mape: 0.3139 - val_mae: 0.0020\n",
      "Epoch 8/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 4.2521e-05 - mape: 455.9558 - mae: 0.0036 - val_loss: 3.7014e-06 - val_mape: 0.3621 - val_mae: 0.0016\n",
      "Epoch 9/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 7.6633e-06 - mape: 363.5911 - mae: 0.0016 - val_loss: 1.6760e-05 - val_mape: 0.9492 - val_mae: 0.0039\n",
      "92/92 [==============================] - 11s 120ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_10 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 153s 238ms/step - loss: 0.0015 - mape: 1306.8208 - mae: 0.0098 - val_loss: 7.5022e-06 - val_mape: 0.4450 - val_mae: 0.0023\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 4.5543e-05 - mape: 1564.5214 - mae: 0.0051 - val_loss: 9.5722e-05 - val_mape: 2.0154 - val_mae: 0.0096\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 1.1230e-04 - mape: 710.1428 - mae: 0.0063 - val_loss: 9.2974e-05 - val_mape: 2.1347 - val_mae: 0.0095\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 3.9356e-05 - mape: 585.9064 - mae: 0.0048 - val_loss: 1.9445e-05 - val_mape: 0.9315 - val_mae: 0.0041\n",
      "92/92 [==============================] - 11s 121ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_11 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 153s 238ms/step - loss: 0.0021 - mape: 1.5067 - mae: 0.0095 - val_loss: 2.3491e-05 - val_mape: 0.8025 - val_mae: 0.0046\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 1.2995e-06 - mape: 0.1448 - mae: 8.8543e-04 - val_loss: 2.4814e-05 - val_mape: 0.8286 - val_mae: 0.0048\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 3.1805e-05 - mape: 0.4998 - mae: 0.0031 - val_loss: 3.6267e-05 - val_mape: 0.9733 - val_mae: 0.0060\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 1.8450e-05 - mape: 0.4029 - mae: 0.0025 - val_loss: 6.9588e-05 - val_mape: 1.3895 - val_mae: 0.0082\n",
      "92/92 [==============================] - 11s 121ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_12 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 153s 237ms/step - loss: 0.0058 - mape: 3.1353 - mae: 0.0258 - val_loss: 5.9250e-04 - val_mape: 5.9573 - val_mae: 0.0215\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 2.0500e-06 - mape: 0.1423 - mae: 0.0011 - val_loss: 5.3154e-04 - val_mape: 5.6300 - val_mae: 0.0203\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 1.3728e-06 - mape: 0.1168 - mae: 9.5252e-04 - val_loss: 4.0501e-04 - val_mape: 4.8068 - val_mae: 0.0171\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 1.2228e-06 - mape: 0.1076 - mae: 8.9970e-04 - val_loss: 3.4456e-04 - val_mape: 4.3661 - val_mae: 0.0154\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 2.0087e-06 - mape: 0.1303 - mae: 0.0011 - val_loss: 2.8957e-04 - val_mape: 4.0044 - val_mae: 0.0141\n",
      "Epoch 6/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 2.3772e-05 - mape: 0.4168 - mae: 0.0036 - val_loss: 1.9904e-04 - val_mape: 3.3653 - val_mae: 0.0119\n",
      "Epoch 7/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 6.7370e-05 - mape: 0.6201 - mae: 0.0053 - val_loss: 3.7273e-04 - val_mape: 4.7484 - val_mae: 0.0172\n",
      "Epoch 8/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 1.0525e-04 - mape: 0.6434 - mae: 0.0055 - val_loss: 9.1947e-04 - val_mape: 7.1733 - val_mae: 0.0253\n",
      "Epoch 9/20\n",
      "635/635 [==============================] - 150s 237ms/step - loss: 3.0840e-06 - mape: 0.1545 - mae: 0.0013 - val_loss: 9.1052e-04 - val_mape: 7.1251 - val_mae: 0.0251\n",
      "92/92 [==============================] - 11s 121ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_13 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 153s 238ms/step - loss: 0.0025 - mape: 1.9873 - mae: 0.0119 - val_loss: 2.1470e-04 - val_mape: 6.1679 - val_mae: 0.0126\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 8.6291e-08 - mape: 0.0369 - mae: 2.2697e-04 - val_loss: 1.9620e-04 - val_mape: 5.8461 - val_mae: 0.0119\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 4.9382e-07 - mape: 0.0603 - mae: 3.9293e-04 - val_loss: 1.9711e-04 - val_mape: 5.8613 - val_mae: 0.0119\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 1.2100e-04 - mape: 0.8979 - mae: 0.0060 - val_loss: 6.5023e-04 - val_mape: 10.7804 - val_mae: 0.0221\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 8.1427e-08 - mape: 0.0348 - mae: 2.1124e-04 - val_loss: 5.5744e-04 - val_mape: 9.7802 - val_mae: 0.0199\n",
      "92/92 [==============================] - 11s 121ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_14 --------\n",
      "Epoch 1/20\n",
      "635/635 [==============================] - 153s 238ms/step - loss: 0.0169 - mape: 45868.8398 - mae: 0.1029 - val_loss: 0.0153 - val_mape: 25.5210 - val_mae: 0.0982\n",
      "Epoch 2/20\n",
      "635/635 [==============================] - 152s 239ms/step - loss: 0.0160 - mape: 48816.4141 - mae: 0.1011 - val_loss: 0.0152 - val_mape: 23.6462 - val_mae: 0.0984\n",
      "Epoch 3/20\n",
      "635/635 [==============================] - 151s 238ms/step - loss: 0.0158 - mape: 47052.8555 - mae: 0.1003 - val_loss: 0.0155 - val_mape: 23.4904 - val_mae: 0.0996\n",
      "Epoch 4/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 0.0158 - mape: 47569.5430 - mae: 0.1003 - val_loss: 0.0169 - val_mape: 23.4585 - val_mae: 0.1039\n",
      "Epoch 5/20\n",
      "635/635 [==============================] - 151s 237ms/step - loss: 0.0157 - mape: 48094.3594 - mae: 0.1000 - val_loss: 0.0183 - val_mape: 23.7127 - val_mae: 0.1081\n",
      "92/92 [==============================] - 11s 120ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>NRMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eIMF_1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_8</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_9</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_10</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_11</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_12</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_13</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_14</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eIMF_15</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MAPE  RMSE   MAE  NRMSE\n",
       "eIMF_1   0.05  0.10  0.08   0.18\n",
       "eIMF_2   0.02  0.04  0.03   0.07\n",
       "eIMF_3   0.00  0.00  0.00   0.01\n",
       "eIMF_4   0.00  0.00  0.00   0.00\n",
       "eIMF_5   0.00  0.00  0.00   0.01\n",
       "eIMF_6   0.00  0.00  0.00   0.01\n",
       "eIMF_7   0.00  0.01  0.00   0.01\n",
       "eIMF_8   0.00  0.00  0.00   0.01\n",
       "eIMF_9   0.00  0.00  0.00   0.00\n",
       "eIMF_10  0.00  0.00  0.00   0.00\n",
       "eIMF_11  0.00  0.01  0.01   0.01\n",
       "eIMF_12  0.09  0.10  0.10   1.26\n",
       "eIMF_13  0.11  0.13  0.11   1.38\n",
       "eIMF_14  0.07  0.08  0.07   0.98\n",
       "eIMF_15  0.06  0.12  0.10   0.23\n",
       "All      0.01  0.01  0.01   0.12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_EEMD_LSTM('Product_0025', epochs=20, time_steps=30, normalize=True, plot=True, metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8382fa7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Total: 0~14 eIMFs, Now: eIMFs_0 --------\n",
      "Epoch 1/20\n",
      "633/633 [==============================] - 166s 258ms/step - loss: 0.0098 - mape: 11.6838 - mae: 0.0748 - val_loss: 0.0104 - val_mape: 13.3846 - val_mae: 0.0807\n",
      "Epoch 2/20\n",
      "633/633 [==============================] - 162s 257ms/step - loss: 0.0081 - mape: 11.0959 - mae: 0.0708 - val_loss: 0.0094 - val_mape: 12.6085 - val_mae: 0.0763\n",
      "Epoch 3/20\n",
      "633/633 [==============================] - 159s 251ms/step - loss: 0.0079 - mape: 11.0414 - mae: 0.0705 - val_loss: 0.0082 - val_mape: 11.6145 - val_mae: 0.0711\n",
      "Epoch 4/20\n",
      "633/633 [==============================] - 158s 249ms/step - loss: 0.0079 - mape: 11.0012 - mae: 0.0701 - val_loss: 0.0087 - val_mape: 11.0721 - val_mae: 0.0748\n",
      "Epoch 5/20\n",
      "633/633 [==============================] - 157s 248ms/step - loss: 0.0071 - mape: 10.4016 - mae: 0.0664 - val_loss: 0.0060 - val_mape: 9.3866 - val_mae: 0.0613\n",
      "Epoch 6/20\n",
      "633/633 [==============================] - 154s 244ms/step - loss: 0.0060 - mape: 9.5519 - mae: 0.0613 - val_loss: 0.0058 - val_mape: 9.5767 - val_mae: 0.0597\n",
      "Epoch 7/20\n",
      "633/633 [==============================] - 151s 239ms/step - loss: 0.0058 - mape: 9.3646 - mae: 0.0600 - val_loss: 0.0071 - val_mape: 10.0010 - val_mae: 0.0679\n",
      "Epoch 8/20\n",
      "633/633 [==============================] - 151s 238ms/step - loss: 0.0057 - mape: 9.2858 - mae: 0.0595 - val_loss: 0.0054 - val_mape: 8.9446 - val_mae: 0.0580\n",
      "Epoch 9/20\n",
      "633/633 [==============================] - 151s 238ms/step - loss: 0.0057 - mape: 9.2938 - mae: 0.0596 - val_loss: 0.0054 - val_mape: 9.1190 - val_mae: 0.0579\n",
      "Epoch 10/20\n",
      "633/633 [==============================] - 150s 237ms/step - loss: 0.0057 - mape: 9.2369 - mae: 0.0592 - val_loss: 0.0056 - val_mape: 9.3684 - val_mae: 0.0586\n",
      "Epoch 11/20\n",
      "633/633 [==============================] - 151s 238ms/step - loss: 0.0056 - mape: 9.2482 - mae: 0.0593 - val_loss: 0.0056 - val_mape: 9.4126 - val_mae: 0.0589\n",
      "90/90 [==============================] - 11s 122ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_1 --------\n",
      "Epoch 1/20\n",
      "633/633 [==============================] - 171s 266ms/step - loss: 0.0023 - mape: 50246.2695 - mae: 0.0231 - val_loss: 9.6853e-04 - val_mape: 3.7764 - val_mae: 0.0195\n",
      "Epoch 2/20\n",
      "633/633 [==============================] - 168s 265ms/step - loss: 9.4596e-04 - mape: 51651.9805 - mae: 0.0181 - val_loss: 9.4213e-04 - val_mape: 3.7186 - val_mae: 0.0192\n",
      "Epoch 3/20\n",
      "633/633 [==============================] - 168s 265ms/step - loss: 9.4794e-04 - mape: 52772.1992 - mae: 0.0183 - val_loss: 9.7609e-04 - val_mape: 3.9303 - val_mae: 0.0198\n",
      "Epoch 4/20\n",
      "633/633 [==============================] - 168s 265ms/step - loss: 9.0158e-04 - mape: 51238.1055 - mae: 0.0177 - val_loss: 8.7844e-04 - val_mape: 3.6235 - val_mae: 0.0183\n",
      "Epoch 5/20\n",
      "633/633 [==============================] - 168s 265ms/step - loss: 8.9697e-04 - mape: 52011.3008 - mae: 0.0182 - val_loss: 8.8050e-04 - val_mape: 3.7639 - val_mae: 0.0189\n",
      "Epoch 6/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 8.1250e-04 - mape: 49645.8164 - mae: 0.0175 - val_loss: 6.4025e-04 - val_mape: 3.1758 - val_mae: 0.0163\n",
      "Epoch 7/20\n",
      "633/633 [==============================] - 169s 266ms/step - loss: 5.2771e-04 - mape: 40854.9141 - mae: 0.0149 - val_loss: 2.5261e-04 - val_mape: 2.0446 - val_mae: 0.0105\n",
      "Epoch 8/20\n",
      "633/633 [==============================] - 167s 265ms/step - loss: 2.0876e-04 - mape: 19213.5234 - mae: 0.0102 - val_loss: 1.3078e-04 - val_mape: 1.6596 - val_mae: 0.0087\n",
      "Epoch 9/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 1.4509e-04 - mape: 7238.2485 - mae: 0.0087 - val_loss: 1.1604e-04 - val_mape: 1.4798 - val_mae: 0.0077\n",
      "Epoch 10/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 1.4498e-04 - mape: 18167.0781 - mae: 0.0087 - val_loss: 2.1679e-04 - val_mape: 2.2339 - val_mae: 0.0114\n",
      "Epoch 11/20\n",
      "633/633 [==============================] - 168s 265ms/step - loss: 1.3874e-04 - mape: 7884.9468 - mae: 0.0086 - val_loss: 1.3455e-04 - val_mape: 1.6206 - val_mae: 0.0083\n",
      "Epoch 12/20\n",
      "633/633 [==============================] - 169s 268ms/step - loss: 1.2132e-04 - mape: 5641.7227 - mae: 0.0081 - val_loss: 1.1483e-04 - val_mape: 1.4234 - val_mae: 0.0074\n",
      "Epoch 13/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 1.4419e-04 - mape: 14568.2646 - mae: 0.0087 - val_loss: 9.8507e-05 - val_mape: 1.3790 - val_mae: 0.0071\n",
      "Epoch 14/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 1.2827e-04 - mape: 14912.4697 - mae: 0.0083 - val_loss: 1.3713e-04 - val_mape: 1.7655 - val_mae: 0.0093\n",
      "Epoch 15/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 1.3043e-04 - mape: 6163.3555 - mae: 0.0083 - val_loss: 1.1898e-04 - val_mape: 1.5121 - val_mae: 0.0078\n",
      "Epoch 16/20\n",
      "633/633 [==============================] - 167s 263ms/step - loss: 1.3731e-04 - mape: 7659.7168 - mae: 0.0085 - val_loss: 1.0374e-04 - val_mape: 1.4658 - val_mae: 0.0077\n",
      "90/90 [==============================] - 13s 137ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_2 --------\n",
      "Epoch 1/20\n",
      "633/633 [==============================] - 169s 264ms/step - loss: 0.0030 - mape: 8.1353 - mae: 0.0278 - val_loss: 6.6845e-04 - val_mape: 3.8459 - val_mae: 0.0172\n",
      "Epoch 2/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 2.8373e-04 - mape: 2.9546 - mae: 0.0117 - val_loss: 1.9295e-04 - val_mape: 2.1257 - val_mae: 0.0088\n",
      "Epoch 3/20\n",
      "633/633 [==============================] - 167s 263ms/step - loss: 1.4173e-04 - mape: 2.2683 - mae: 0.0088 - val_loss: 2.0801e-04 - val_mape: 2.6192 - val_mae: 0.0123\n",
      "Epoch 4/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 7.5129e-05 - mape: 1.5170 - mae: 0.0065 - val_loss: 9.4181e-05 - val_mape: 1.8098 - val_mae: 0.0081\n",
      "Epoch 5/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 5.8605e-05 - mape: 1.3184 - mae: 0.0058 - val_loss: 5.7857e-05 - val_mape: 1.3231 - val_mae: 0.0060\n",
      "Epoch 6/20\n",
      "633/633 [==============================] - 167s 263ms/step - loss: 4.7276e-05 - mape: 1.1914 - mae: 0.0053 - val_loss: 3.4669e-05 - val_mape: 0.9203 - val_mae: 0.0040\n",
      "Epoch 7/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 3.2445e-05 - mape: 0.9880 - mae: 0.0043 - val_loss: 5.8685e-05 - val_mape: 1.4634 - val_mae: 0.0067\n",
      "Epoch 8/20\n",
      "633/633 [==============================] - 167s 263ms/step - loss: 4.8507e-05 - mape: 1.2069 - mae: 0.0052 - val_loss: 1.7904e-05 - val_mape: 0.6545 - val_mae: 0.0029\n",
      "Epoch 9/20\n",
      "633/633 [==============================] - 167s 263ms/step - loss: 2.7763e-05 - mape: 0.8952 - mae: 0.0040 - val_loss: 6.3118e-05 - val_mape: 1.4824 - val_mae: 0.0070\n",
      "Epoch 10/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 2.6185e-05 - mape: 0.8946 - mae: 0.0040 - val_loss: 9.7211e-05 - val_mape: 1.9753 - val_mae: 0.0093\n",
      "Epoch 11/20\n",
      "633/633 [==============================] - 168s 265ms/step - loss: 2.8476e-05 - mape: 0.9783 - mae: 0.0041 - val_loss: 1.3177e-05 - val_mape: 0.5600 - val_mae: 0.0025\n",
      "Epoch 12/20\n",
      "633/633 [==============================] - 167s 263ms/step - loss: 2.5313e-05 - mape: 0.8753 - mae: 0.0039 - val_loss: 5.1039e-05 - val_mape: 1.3915 - val_mae: 0.0066\n",
      "Epoch 13/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 3.1326e-05 - mape: 1.0157 - mae: 0.0041 - val_loss: 1.0273e-05 - val_mape: 0.5016 - val_mae: 0.0023\n",
      "Epoch 14/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 1.6990e-05 - mape: 0.7312 - mae: 0.0031 - val_loss: 4.9389e-04 - val_mape: 4.6494 - val_mae: 0.0220\n",
      "Epoch 15/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 2.7749e-05 - mape: 0.8974 - mae: 0.0038 - val_loss: 3.7143e-05 - val_mape: 1.1727 - val_mae: 0.0054\n",
      "Epoch 16/20\n",
      "633/633 [==============================] - 167s 264ms/step - loss: 1.7167e-05 - mape: 0.7283 - mae: 0.0031 - val_loss: 1.0834e-05 - val_mape: 0.5606 - val_mae: 0.0025\n",
      "90/90 [==============================] - 13s 137ms/step\n",
      "--------Total: 0~14 eIMFs, Now: eIMFs_3 --------\n",
      "Epoch 1/20\n",
      "633/633 [==============================] - 170s 265ms/step - loss: 0.0017 - mape: 8165.2456 - mae: 0.0218 - val_loss: 2.4002e-04 - val_mape: 3.5291 - val_mae: 0.0132\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 167s 263ms/step - loss: 8.7729e-05 - mape: 3520.4307 - mae: 0.0072 - val_loss: 1.4286e-04 - val_mape: 2.8525 - val_mae: 0.0105\n",
      "Epoch 3/20\n",
      "633/633 [==============================] - 166s 263ms/step - loss: 5.9305e-05 - mape: 3903.4475 - mae: 0.0060 - val_loss: 2.8250e-04 - val_mape: 4.2563 - val_mae: 0.0160\n",
      "Epoch 4/20\n",
      "633/633 [==============================] - 166s 263ms/step - loss: 4.8069e-05 - mape: 989.3499 - mae: 0.0052 - val_loss: 2.7046e-04 - val_mape: 3.9637 - val_mae: 0.0154\n",
      "Epoch 5/20\n",
      "633/633 [==============================] - 166s 262ms/step - loss: 4.4531e-05 - mape: 2725.5481 - mae: 0.0050 - val_loss: 1.6856e-05 - val_mape: 0.8826 - val_mae: 0.0031\n",
      "Epoch 6/20\n",
      " 91/633 [===>..........................] - ETA: 2:39 - loss: 2.8155e-05 - mape: 1.1565 - mae: 0.0042"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mexecute_EEMD_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct_0739\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m, in \u001b[0;36mexecute_EEMD_LSTM\u001b[1;34m(product_code, eemd_trials, time_steps, epochs, normalize, plot, metric)\u001b[0m\n\u001b[0;32m      9\u001b[0m all_eIMFs_dict \u001b[38;5;241m=\u001b[39m extract_eIMFs(all_eIMFs_df, nIMFs)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# EEMD+LSTM 실행\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m model_dict, pred_dict \u001b[38;5;241m=\u001b[39m \u001b[43mEEMD_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_eIMFs_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#dictionary, time_steps, epochs\u001b[39;00m\n\u001b[0;32m     12\u001b[0m all_result_df \u001b[38;5;241m=\u001b[39m make_all_result_df(pred_dict)\n\u001b[0;32m     14\u001b[0m result_df \u001b[38;5;241m=\u001b[39m make_metric_df(product_code, pred_dict, all_result_df, normalize)\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mEEMD_LSTM\u001b[1;34m(all_eIMFs_dict, time_steps, epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m X_train, y_train, X_val, y_val, X_test, y_test, sc \u001b[38;5;241m=\u001b[39m ts_train_val_test(eIMF_df, time_steps)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# LSTM 모델 학습 및 저장\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m my_LSTM_model, LSTM_prediction, LSTM_prediction_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mLSTM_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m model_dict[i] \u001b[38;5;241m=\u001b[39m my_LSTM_model \u001b[38;5;66;03m# 딕셔너리에 모델 정보 저장\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 예측 결과 저장\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m, in \u001b[0;36mLSTM_model\u001b[1;34m(X_train, y_train, X_val, y_val, X_test, sc, epochs)\u001b[0m\n\u001b[0;32m     25\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 모델 Fitting\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mmy_LSTM_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 입력 데이터\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m                  \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 출력 데이터\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# epoch 수\u001b[39;49;00m\n\u001b[0;32m     31\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# batch size\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m# validation에 따른 조기종료\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 학습 상태를 출력\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Test 데이터 예측\u001b[39;00m\n\u001b[0;32m     37\u001b[0m LSTM_prediction \u001b[38;5;241m=\u001b[39m my_LSTM_model\u001b[38;5;241m.\u001b[39mpredict(X_test) \u001b[38;5;66;03m# 예측값 얻기\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\eemd\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "execute_EEMD_LSTM('Product_0739', epochs=20, time_steps=30, normalize=True, plot=True, metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ff367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
